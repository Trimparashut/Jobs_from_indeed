{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import time\n",
    "from random import randint\n",
    "import socket\n",
    "import socks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_job_title(soup): \n",
    "    for i in soup.find_all(name=\"div\", attrs={'class':\"css-17x2pwl e11nt52q5\"}):\n",
    "        job = i.text\n",
    "    return job\n",
    "\n",
    "def get_company(soup): \n",
    "    for i in soup.find_all(name=\"div\", attrs={'class':\"css-16nw49e e11nt52q1\"}):\n",
    "        comp = i.text.split('.css')[0]\n",
    "    return comp\n",
    "\n",
    "def get_location(soup): \n",
    "    for i in soup.find_all(name=\"div\", attrs={'class':\"css-13et3b1 e11nt52q2\"}):\n",
    "        loc = i.text\n",
    "    return loc\n",
    "\n",
    "def get_rating(soup):\n",
    "    for i in soup.find_all(name=\"span\", attrs={'class':\"css-1pmc6te e11nt52q3\"}):\n",
    "        rating = i.text.split('.css')[0]\n",
    "    return rating\n",
    "\n",
    "def get_links(soup):\n",
    "    links = []\n",
    "    for i in soup.find_all(name=\"a\", attrs={\"target\":\"_blank\"}):\n",
    "        for j in i:\n",
    "            href = i.get('href')\n",
    "            if '/partner/jobListing.htm' in href:\n",
    "                links.append(href)\n",
    "    return list(set(links))\n",
    "\n",
    "def get_soup(url):\n",
    "    page = requests.get(url)#,headers = {'User-agent':'Mozilla/5.0 (compatible; ABrowse 0.4; Syllable)'})\n",
    "    if page.status_code == 200:\n",
    "        soup = BeautifulSoup(page.text, \"html.parser\")\n",
    "    else:\n",
    "        print('Status code is not 200')\n",
    "        soup = 0\n",
    "        time.sleep(120)\n",
    "    return soup\n",
    "\n",
    "def get_job_descr(soup):\n",
    "    text=''\n",
    "    for i in soup.find_all(name=\"div\", attrs={\"class\":\"css-jfggi0 e1eh6fgm2\"}):\n",
    "        for j in i.find_all(name=\"div\", attrs={\"class\":\"desc css-58vpdc ecgq1xb3\"}):\n",
    "            text += ' ' + (str(j.text))\n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# socks.set_default_proxy(socks.SOCKS5,'localhost',9150)\n",
    "# socket.socket=socks.socksocket\n",
    "\n",
    "data = pd.DataFrame(columns=['title', 'company_rating', \n",
    "                             'company', 'location', 'description', 'url'])\n",
    "link = 'https://www.glassdoor.com/Job/tel-aviv-yafo-data-scientist-jobs-SRCH_IL.0,13_IC2421096_KO14,28.htm?sortBy=date_desc'\n",
    "\n",
    "soup = get_soup(link)\n",
    "links = get_links(soup)\n",
    "df = pd.DataFrame(columns=data.columns)\n",
    "df['url'] = links\n",
    "for i,l in enumerate(links):\n",
    "    link = 'https://www.glassdoor.com' +l\n",
    "#     df.loc[i]['url'] = link\n",
    "    print(link)\n",
    "    page = get_soup(link)\n",
    "    df.loc[i]['description'] = get_job_descr(page)\n",
    "    df.loc[i]['company_rating'] = get_rating(page)\n",
    "    df.loc[i]['title'] = get_job_title(page)\n",
    "    df.loc[i]['company'] = get_company(page)\n",
    "    df.loc[i]['location'] = get_location(page)\n",
    "    time.sleep(randint(3,5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data.dropna(inplace=True)\n",
    "data.drop_duplicates(inplace=True)\n",
    "data['description'] = data.description.map(lambda x: clear(x))\n",
    "data.reset_index(inplace=True, drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv('new_g.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
